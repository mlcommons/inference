{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A short tutorial how to use the mlperf inference reference benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrapped all inference models into a single benchmark app. The benchmark app will read the propper dataset, preprocesses it and interface with the backend. Traffic is generated by loadgen, which depending on the desired mode drives the desired traffic to the benchmark app. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benchmark app uses a shell script to simplify command line options and the user can pick backend, model and device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ./run_local.sh tf|onnxruntime|pytorch|tflite [resnet50|mobilenet|ssd-mobilenet|ssd-resnet34] [cpu|gpu]\r\n"
     ]
    }
   ],
   "source": [
    "!./run_local.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the benchmark, device on model and dataset and set the environment variable ```MODEL_DIR``` and ```DATA_DIR```. For this tutorial we use onnxruntime, mobilenet and a fake imagetnet dataset with a few images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnxruntime in /opt/anaconda3/lib/python3.6/site-packages (0.4.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - download the model. You find the links to the models [here](https://github.com/mlperf/inference/tree/master/cloud/image_classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://zenodo.org/record/3157894/files/mobilenet_v1_1.0_224.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - download the dataset. For this tutorial we create a small, fake dataset that pretents to be imagenet.\n",
    "Normally you'd need to download imagenet2012/valiation for image classification or coco2017 for object detections. Links and instructions can be found in the [README](README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: tools/make_fake_imagetnet.sh: not found\r\n"
     ]
    }
   ],
   "source": [
    "!tools/make_fake_imagenet.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - tell the benchmark where to find model and data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['MODEL_DIR'] = os.getcwd()\n",
    "os.environ['DATA_DIR'] = \"fake_imagenet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['EXTRA_OPS'] =\"--queries-offline 20 --time 10 --max-latency 0.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - run the benchmark.\n",
    "We add the ```--time 10``` option to limit the time to 10 seconds in this tutorial. For submission you must keep default options. ```--accuracy``` is required for mlperf submission to validate correctnes of inference results. For testing it is not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ source ./run_common.sh\n",
      "++ '[' 4 -lt 1 ']'\n",
      "++ '[' xfake_imagenet == x ']'\n",
      "++ '[' x/home/gs/inference/cloud/image_classification == x ']'\n",
      "++ backend=tf\n",
      "++ model=resnet50\n",
      "++ device=cpu\n",
      "++ for i in '$*'\n",
      "++ case $i in\n",
      "++ backend=onnxruntime\n",
      "++ shift\n",
      "++ for i in '$*'\n",
      "++ case $i in\n",
      "++ model=mobilenet\n",
      "++ shift\n",
      "++ for i in '$*'\n",
      "++ case $i in\n",
      "++ device=cpu\n",
      "++ shift\n",
      "++ for i in '$*'\n",
      "++ case $i in\n",
      "++ '[' cpu == cpu ']'\n",
      "++ export CUDA_VISIBLE_DEVICES=\n",
      "++ CUDA_VISIBLE_DEVICES=\n",
      "++ name=mobilenet-onnxruntime\n",
      "++ extra_args=\n",
      "++ '[' mobilenet-onnxruntime == resnet50-tf ']'\n",
      "++ '[' mobilenet-onnxruntime == mobilenet-tf ']'\n",
      "++ '[' mobilenet-onnxruntime == ssd-mobilenet-tf ']'\n",
      "++ '[' mobilenet-onnxruntime == ssd-resnet34-tf ']'\n",
      "++ '[' mobilenet-onnxruntime == resnet50-onnxruntime ']'\n",
      "++ '[' mobilenet-onnxruntime == mobilenet-onnxruntime ']'\n",
      "++ model_path=/home/gs/inference/cloud/image_classification/mobilenet_v1_1.0_224.onnx\n",
      "++ profile=mobilenet-onnxruntime\n",
      "++ '[' mobilenet-onnxruntime == ssd-mobilenet-onnxruntime ']'\n",
      "++ '[' mobilenet-onnxruntime == ssd-resnet34-onnxruntime ']'\n",
      "++ '[' mobilenet-onnxruntime == resnet50-pytorch ']'\n",
      "++ '[' mobilenet-onnxruntime == mobilenet-pytorch ']'\n",
      "++ '[' mobilenet-onnxruntime == ssd-resnet34-pytorch ']'\n",
      "++ '[' mobilenet-onnxruntime == resnet50-tflite ']'\n",
      "++ '[' mobilenet-onnxruntime == mobilenet-tflite ']'\n",
      "++ name=mobilenet-onnxruntime-cpu\n",
      "++ EXTRA_OPS=' --queries-offline 20 --time 10 --max-latency 0.2'\n",
      "+ common_opt=\n",
      "+ dataset='--dataset-path fake_imagenet'\n",
      "++ pwd\n",
      "+ OUTPUT_DIR=/home/gs/inference/cloud/image_classification/output/mobilenet-onnxruntime-cpu\n",
      "+ '[' '!' -d /home/gs/inference/cloud/image_classification/output/mobilenet-onnxruntime-cpu ']'\n",
      "+ python python/main.py --profile mobilenet-onnxruntime --model /home/gs/inference/cloud/image_classification/mobilenet_v1_1.0_224.onnx --dataset-path fake_imagenet --output /home/gs/inference/cloud/image_classification/output/mobilenet-onnxruntime-cpu/results.json --queries-offline 20 --time 10 --max-latency 0.2 --accuracy\n",
      "INFO:main:Namespace(accuracy=True, backend='onnxruntime', cache=0, count=None, data_format=None, dataset='imagenet_mobilenet', dataset_list=None, dataset_path='fake_imagenet', inputs=None, max_batchsize=128, max_latency=[0.2], model='/home/gs/inference/cloud/image_classification/mobilenet_v1_1.0_224.onnx', output='/home/gs/inference/cloud/image_classification/output/mobilenet-onnxruntime-cpu/results.json', outputs=['MobilenetV1/Predictions/Reshape_1:0'], profile='mobilenet-onnxruntime', qps=10, queries_multi=24576, queries_offline=20, queries_single=1024, scenario=[TestScenario.SingleStream], threads=2, time=10)\n",
      "INFO:imagenet:loaded 8 images, cache=0, took=0.0sec\n",
      "INFO:main:starting accuracy pass on 8 items\n",
      "Accuracy qps=20.34, mean=0.047533, time=0.39, acc=87.50, queries=8, tiles=50.0:0.0453,80.0:0.0475,90.0:0.0516,95.0:0.0559,99.0:0.0593,99.9:0.0600\n",
      "INFO:main:starting TestScenario.SingleStream, latency=1.0\n",
      "TestScenario.SingleStream-1.0 qps=20.25, mean=0.049239, time=10.07, acc=0.00, queries=204, tiles=50.0:0.0453,80.0:0.0463,90.0:0.0475,95.0:0.0849,99.0:0.1048,99.9:0.1577\n"
     ]
    }
   ],
   "source": [
    "!bash -x ./run_local.sh onnxruntime mobilenet cpu  --accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:main:Namespace(accuracy=True, backend='onnxruntime', cache=0, count=None, data_format=None, dataset='imagenet_mobilenet', dataset_list=None, dataset_path='fake_imagenet', inputs=None, max_batchsize=128, max_latency=[0.01, 0.05, 0.1], model='/home/gs/resnet_for_mlperf/mobilenet_v1_1.0_224.onnx', output='/home/gs/inference/cloud/image_classification/output/mobilenet-onnxruntime-cpu/results.json', outputs=['MobilenetV1/Predictions/Reshape_1:0'], profile='mobilenet-onnxruntime', qps=10, queries_multi=24576, queries_offline=24576, queries_single=1024, scenario=[TestScenario.SingleStream, TestScenario.MultiStream, TestScenario.Server, TestScenario.Offline], threads=2, time=10)\n",
      "INFO:imagenet:loaded 8 images, cache=0, took=0.0sec\n",
      "INFO:main:starting accuracy pass on 8 items\n",
      "Accuracy qps=16.48, mean=0.059025, time=0.49, acc=87.50, queries=8, tiles=50.0:0.0558,80.0:0.0618,90.0:0.0672,95.0:0.0700,99.0:0.0722,99.9:0.0728\n",
      "INFO:main:starting TestScenario.SingleStream, latency=1.0\n",
      "TestScenario.SingleStream-1.0 qps=17.58, mean=0.056729, time=10.12, acc=0.00, queries=178, tiles=50.0:0.0560,80.0:0.0571,90.0:0.0575,95.0:0.0583,99.0:0.0680,99.9:0.1093\n",
      "INFO:main:starting TestScenario.MultiStream, latency=1.0\n",
      "TestScenario.MultiStream-1.0 qps=14.92, mean=1.034430, time=11.26, acc=0.00, queries=168, tiles=50.0:1.0302,80.0:1.1229,90.0:1.1482,95.0:1.1667,99.0:1.2008,99.9:1.2008\n",
      "INFO:main:starting TestScenario.Server, latency=0.01\n",
      "TestScenario.Server-0.01 qps=7.97, mean=0.091574, time=0.13, acc=0.00, queries=1, tiles=50.0:0.0916,80.0:0.0916,90.0:0.0916,95.0:0.0916,99.0:0.0916,99.9:0.0916\n",
      "INFO:main:starting TestScenario.Server, latency=0.05\n",
      "TestScenario.Server-0.05 qps=9.56, mean=0.172555, time=0.31, acc=0.00, queries=3, tiles=50.0:0.1575,80.0:0.1955,90.0:0.2081,95.0:0.2144,99.0:0.2195,99.9:0.2206\n",
      "INFO:main:starting TestScenario.Server, latency=0.1\n",
      "TestScenario.Server-0.1 qps=11.90, mean=0.186982, time=2.86, acc=0.00, queries=34, tiles=50.0:0.1649,80.0:0.2580,90.0:0.2784,95.0:0.2913,99.0:0.3195,99.9:0.3247\n",
      "INFO:main:starting TestScenario.Offline, latency=1.0\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!./run_local.sh onnxruntime mobilenet cpu --accuracy --scenario SingleStream,MultiStream,Server,Offline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
