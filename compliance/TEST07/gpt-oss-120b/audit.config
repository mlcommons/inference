# The format of this config file is 'key = value'.
# The key has the format 'model.scenario.key'. Value is mostly int64_t.
# Model maybe '*' as wildcard. In that case the value applies to all models.
# All times are in milli seconds

# TEST07: Verify accuracy in performance mode for workloads with separate accuracy/performance datasets
# This test logs ALL samples and verifies accuracy against a compliance threshold.

# mode dictionary (0 = submission, 1 = accuracy, 2 = performance, 3 = find peak perf)
*.*.mode = 2

# Use a fixed RNG seed for reproducibility
*.*.accuracy_log_rng_seed = 720381539243781796

# Log ALL samples - set to a value >= total dataset size
*.*.accuracy_log_sampling_target = 990

# Ensure we run through all samples
*.*.min_query_count = 990
*.*.min_duration = 0

# Turn off sample concatenation for accurate logging
*.*.sample_concatenate_permutation = 0

# =============================================================================
# TEST07 Compliance Threshold (read by run_verification.py, not by LoadGen)
# =============================================================================
# Minimum accuracy score required to pass TEST07 verification
#
# For gpt-oss-120b:
# - dataset: gpqa-compliance-dataset (acc_eval_compliance_gpqa.parquet)
# - compliance-score-threshold: 60.698%
*.*.test07_accuracy_threshold = 60.698
