# User configuration for gpt-oss MLPerf inference
# Override default settings from mlperf.conf here

# Offline scenario
gpt-oss.Offline.target_qps = 1.0
gpt-oss.Offline.min_duration = 60000
gpt-oss.Offline.min_query_count = 100

# Server scenario
gpt-oss.Server.target_qps = 1.0
gpt-oss.Server.min_duration = 60000
gpt-oss.Server.target_latency = 0
gpt-oss.Server.ttft_latency = 2000
gpt-oss.Server.tpot_latency = 20

# SingleStream scenario (if needed)
gpt-oss.SingleStream.target_latency = 1000
gpt-oss.SingleStream.min_duration = 60000

# Performance sample count
# gpt-oss.*.performance_sample_count_override = 8036

