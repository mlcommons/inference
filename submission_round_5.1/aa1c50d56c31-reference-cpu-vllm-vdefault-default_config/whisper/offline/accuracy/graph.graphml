<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <graph edgedefault="directed">
    <node id="app-mlperf-inference,d775cac873ee4231 ( reference,_whisper,_vllm,_cpu,_valid,_r5.1-dev_default,_offline )" />
    <node id="detect,os" />
    <node id="get,sys-utils-cm" />
    <node id="get,python" />
    <node id="get,mlcommons,inference,src,_repo.https://github.com/anandhu-eng/inference,_branch.whisper-fix" />
    <node id="get-mlperf-inference-utils,e341e5f86d8342e5" />
    <node id="get,mlperf,inference,src,_repo.https://github.com/anandhu-eng/inference,_branch.whisper-fix" />
    <node id="get,mlperf,inference,utils" />
    <node id="app-mlperf-inference-mlcommons-python,ff149e9781fc4b65 ( cpu,_offline,_whisper,_vllm,_fp32 )" />
    <node id="detect-cpu,586c8a43320142f7" />
    <node id="detect,cpu" />
    <node id="install-vllm-from-src,_cpu" />
    <node id="generate-mlperf-inference-user-conf,3af4475745964b93 ( wg-inference )" />
    <node id="get-mlperf-inference-sut-configs,c2fbf72009e2445b" />
    <node id="get,cache,dir,_name.mlperf-inference-sut-configs" />
    <node id="get,sut,configs" />
    <node id="generate,user-conf,mlperf,inference,_wg-inference" />
    <node id="get,loadgen,_wg-inference" />
    <node id="get,mlcommons,inference,src" />
    <node id="get-generic-python-lib,94b62a682bc44791 ( package.psutil )" />
    <node id="get,python3" />
    <node id="get,generic-python-lib,_package.psutil" />
    <node id="get-generic-python-lib,94b62a682bc44791 ( package.py-libnuma )" />
    <node id="get,generic-python-lib,_package.py-libnuma" />
    <node id="get,generic-sys-util,_libnuma-dev" />
    <node id="get-generic-python-lib,94b62a682bc44791 ( package.setuptools-scm )" />
    <node id="get,generic-python-lib,_package.setuptools-scm" />
    <node id="get-generic-python-lib,94b62a682bc44791 ( package.librosa )" />
    <node id="get,generic-python-lib,_package.librosa" />
    <node id="get-generic-python-lib,94b62a682bc44791 ( package.transformers )" />
    <node id="get,generic-python-lib,_package.transformers" />
    <node id="get-generic-python-lib,94b62a682bc44791 ( package.openai-whisper )" />
    <node id="get,generic-python-lib,_package.openai-whisper" />
    <node id="get,ml-model,whisper,_rclone,_mlc" />
    <node id="get,dataset,whisper,_preprocessed,_mlc,_rclone" />
    <edge source="app-mlperf-inference,d775cac873ee4231 ( reference,_whisper,_vllm,_cpu,_valid,_r5.1-dev_default,_offline )" target="detect,os" />
    <edge source="app-mlperf-inference,d775cac873ee4231 ( reference,_whisper,_vllm,_cpu,_valid,_r5.1-dev_default,_offline )" target="get,sys-utils-cm" />
    <edge source="app-mlperf-inference,d775cac873ee4231 ( reference,_whisper,_vllm,_cpu,_valid,_r5.1-dev_default,_offline )" target="get,python" />
    <edge source="app-mlperf-inference,d775cac873ee4231 ( reference,_whisper,_vllm,_cpu,_valid,_r5.1-dev_default,_offline )" target="get,mlcommons,inference,src,_repo.https://github.com/anandhu-eng/inference,_branch.whisper-fix" />
    <edge source="app-mlperf-inference,d775cac873ee4231 ( reference,_whisper,_vllm,_cpu,_valid,_r5.1-dev_default,_offline )" target="get,mlperf,inference,utils" />
    <edge source="get-mlperf-inference-utils,e341e5f86d8342e5" target="get,mlperf,inference,src,_repo.https://github.com/anandhu-eng/inference,_branch.whisper-fix" />
    <edge source="app-mlperf-inference-mlcommons-python,ff149e9781fc4b65 ( cpu,_offline,_whisper,_vllm,_fp32 )" target="detect,os" />
    <edge source="app-mlperf-inference-mlcommons-python,ff149e9781fc4b65 ( cpu,_offline,_whisper,_vllm,_fp32 )" target="detect,cpu" />
    <edge source="app-mlperf-inference-mlcommons-python,ff149e9781fc4b65 ( cpu,_offline,_whisper,_vllm,_fp32 )" target="get,sys-utils-cm" />
    <edge source="app-mlperf-inference-mlcommons-python,ff149e9781fc4b65 ( cpu,_offline,_whisper,_vllm,_fp32 )" target="get,python" />
    <edge source="app-mlperf-inference-mlcommons-python,ff149e9781fc4b65 ( cpu,_offline,_whisper,_vllm,_fp32 )" target="install-vllm-from-src,_cpu" />
    <edge source="app-mlperf-inference-mlcommons-python,ff149e9781fc4b65 ( cpu,_offline,_whisper,_vllm,_fp32 )" target="generate,user-conf,mlperf,inference,_wg-inference" />
    <edge source="app-mlperf-inference-mlcommons-python,ff149e9781fc4b65 ( cpu,_offline,_whisper,_vllm,_fp32 )" target="get,loadgen,_wg-inference" />
    <edge source="app-mlperf-inference-mlcommons-python,ff149e9781fc4b65 ( cpu,_offline,_whisper,_vllm,_fp32 )" target="get,mlcommons,inference,src,_repo.https://github.com/anandhu-eng/inference,_branch.whisper-fix" />
    <edge source="app-mlperf-inference-mlcommons-python,ff149e9781fc4b65 ( cpu,_offline,_whisper,_vllm,_fp32 )" target="get,mlcommons,inference,src" />
    <edge source="app-mlperf-inference-mlcommons-python,ff149e9781fc4b65 ( cpu,_offline,_whisper,_vllm,_fp32 )" target="get,generic-python-lib,_package.psutil" />
    <edge source="app-mlperf-inference-mlcommons-python,ff149e9781fc4b65 ( cpu,_offline,_whisper,_vllm,_fp32 )" target="get,generic-python-lib,_package.py-libnuma" />
    <edge source="app-mlperf-inference-mlcommons-python,ff149e9781fc4b65 ( cpu,_offline,_whisper,_vllm,_fp32 )" target="get,generic-sys-util,_libnuma-dev" />
    <edge source="app-mlperf-inference-mlcommons-python,ff149e9781fc4b65 ( cpu,_offline,_whisper,_vllm,_fp32 )" target="get,generic-python-lib,_package.setuptools-scm" />
    <edge source="app-mlperf-inference-mlcommons-python,ff149e9781fc4b65 ( cpu,_offline,_whisper,_vllm,_fp32 )" target="get,generic-python-lib,_package.librosa" />
    <edge source="app-mlperf-inference-mlcommons-python,ff149e9781fc4b65 ( cpu,_offline,_whisper,_vllm,_fp32 )" target="get,generic-python-lib,_package.transformers" />
    <edge source="app-mlperf-inference-mlcommons-python,ff149e9781fc4b65 ( cpu,_offline,_whisper,_vllm,_fp32 )" target="get,generic-python-lib,_package.openai-whisper" />
    <edge source="app-mlperf-inference-mlcommons-python,ff149e9781fc4b65 ( cpu,_offline,_whisper,_vllm,_fp32 )" target="get,ml-model,whisper,_rclone,_mlc" />
    <edge source="app-mlperf-inference-mlcommons-python,ff149e9781fc4b65 ( cpu,_offline,_whisper,_vllm,_fp32 )" target="get,dataset,whisper,_preprocessed,_mlc,_rclone" />
    <edge source="detect-cpu,586c8a43320142f7" target="detect,os" />
    <edge source="generate-mlperf-inference-user-conf,3af4475745964b93 ( wg-inference )" target="detect,os" />
    <edge source="generate-mlperf-inference-user-conf,3af4475745964b93 ( wg-inference )" target="detect,cpu" />
    <edge source="generate-mlperf-inference-user-conf,3af4475745964b93 ( wg-inference )" target="get,python" />
    <edge source="generate-mlperf-inference-user-conf,3af4475745964b93 ( wg-inference )" target="get,sut,configs" />
    <edge source="generate-mlperf-inference-user-conf,3af4475745964b93 ( wg-inference )" target="get,mlcommons,inference,src,_repo.https://github.com/anandhu-eng/inference,_branch.whisper-fix" />
    <edge source="get-mlperf-inference-sut-configs,c2fbf72009e2445b" target="get,cache,dir,_name.mlperf-inference-sut-configs" />
    <edge source="get-generic-python-lib,94b62a682bc44791 ( package.psutil )" target="get,python3" />
    <edge source="get-generic-python-lib,94b62a682bc44791 ( package.py-libnuma )" target="get,python3" />
    <edge source="get-generic-python-lib,94b62a682bc44791 ( package.setuptools-scm )" target="get,python3" />
    <edge source="get-generic-python-lib,94b62a682bc44791 ( package.librosa )" target="get,python3" />
    <edge source="get-generic-python-lib,94b62a682bc44791 ( package.transformers )" target="get,python3" />
    <edge source="get-generic-python-lib,94b62a682bc44791 ( package.openai-whisper )" target="get,python3" />
  </graph>
</graphml>
