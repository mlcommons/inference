python3 python/main.py --profile retinanet-onnxruntime --model "/home/mlcuser/MLC/repos/local/cache/download-file_get-ml-model-mo_833148bf/resnext50_32x4d_fpn.onnx" --dataset-path /home/mlcuser/MLC/repos/local/cache/get-preprocessed-dataset-openimages_aeaec90d --output "/home/mlcuser/MLC/repos/local/cache/get-mlperf-inference-results-dir_426d7d65/valid_results/a18cbc095633-reference-gpu-onnxruntime-v1.22.0-cu124/retinanet/server/TEST01" --scenario Server --max-batchsize 1 --threads 1 --user_conf /home/mlcuser/MLC/repos/mlcommons@mlperf-automations/script/generate-mlperf-inference-user-conf/tmp/4590cf16d3854b27a3105bf8029e672d.conf --audit /home/mlcuser/MLC/repos/local/cache/get-git-repo_inference-src_c44b7c4a/inference/compliance/nvidia/TEST01/retinanet/audit.config --use_preprocessed_dataset --cache_dir /home/mlcuser/MLC/repos/local/cache/get-preprocessed-dataset-openimages_aeaec90d --dataset-list /home/mlcuser/MLC/repos/local/cache/get-preprocessed-dataset-openimages_aeaec90d/annotations/openimages-mlperf.json
INFO:main:Namespace(dataset='openimages-800-retinanet-onnx', dataset_path='/home/mlcuser/MLC/repos/local/cache/get-preprocessed-dataset-openimages_aeaec90d', dataset_list='/home/mlcuser/MLC/repos/local/cache/get-preprocessed-dataset-openimages_aeaec90d/annotations/openimages-mlperf.json', data_format=None, profile='retinanet-onnxruntime', scenario='Server', max_batchsize=1, model='/home/mlcuser/MLC/repos/local/cache/download-file_get-ml-model-mo_833148bf/resnext50_32x4d_fpn.onnx', output='/home/mlcuser/MLC/repos/local/cache/get-mlperf-inference-results-dir_426d7d65/valid_results/a18cbc095633-reference-gpu-onnxruntime-v1.22.0-cu124/retinanet/server/TEST01', inputs=['images'], outputs=['boxes', 'labels', 'scores'], backend='onnxruntime', device=None, model_name='retinanet', threads=1, qps=None, cache=0, cache_dir='/home/mlcuser/MLC/repos/local/cache/get-preprocessed-dataset-openimages_aeaec90d', preprocessed_dir=None, use_preprocessed_dataset=True, accuracy=False, find_peak_performance=False, debug=False, user_conf='/home/mlcuser/MLC/repos/mlcommons@mlperf-automations/script/generate-mlperf-inference-user-conf/tmp/4590cf16d3854b27a3105bf8029e672d.conf', audit_conf='/home/mlcuser/MLC/repos/local/cache/get-git-repo_inference-src_c44b7c4a/inference/compliance/nvidia/TEST01/retinanet/audit.config', time=None, count=None, performance_sample_count=None, max_latency=None, samples_per_query=8)
INFO:coco:loaded 24781 images, cache=0, already_preprocessed=True, took=1.6sec
[0;93m2025-07-12 23:57:18.319989239 [W:onnxruntime:, session_state.cc:1280 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[m
[0;93m2025-07-12 23:57:18.320026421 [W:onnxruntime:, session_state.cc:1282 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[m
INFO:main:starting TestScenario.Server
TestScenario.Server qps=0.95, mean=0.0388, time=601.941, queries=574, tiles=50.0:0.0377,80.0:0.0393,90.0:0.0407,95.0:0.0420,99.0:0.0667,99.9:0.0740
