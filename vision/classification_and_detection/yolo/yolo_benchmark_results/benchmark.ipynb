{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b44461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Timestamp: 2025-10-29T22:59:48\n",
      "Host: macOS-26.0.1-arm64-arm-64bit | Python: 3.11.13 | Processor: arm\n",
      "VAL_DIR: /Volumes/T7 Shield/MLCommon/yolo/datasets/coco/images/val2017\n",
      "DATA_YAML: /Volumes/T7 Shield/MLCommon/yolo/datasets/coco_val_only.yaml\n",
      "Models: yolo11s.pt\n",
      "--------------------------------------------------------------------------------\n",
      "Discovered images: 5000\n",
      "\n",
      "[yolo11s] --- EXPORT + EVAL ---\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s.pt to 'yolo11s.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 18.4MB 38.2MB/s 0.5s0.4s<0.1s\n",
      "Ultralytics 8.3.220 üöÄ Python-3.11.13 torch-2.9.0 CPU (Apple M1 Pro)\n",
      "YOLO11s summary (fused): 100 layers, 9,443,760 parameters, 0 gradients, 21.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11s.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (18.4 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Torch version 2.9.0 has not been tested with coremltools. You may run into unexpected errors. Torch 2.5.0 is the most recent version that has been tested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mCoreML:\u001b[0m starting export with coremltools 8.3.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuple detected at graph output. This will be flattened in the converted model.\n",
      "Converting PyTorch Frontend ==> MIL Ops: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 710/712 [00:00<00:00, 7385.46 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 160.66 passes/s]\n",
      "Running MIL default pipeline: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [00:01<00:00, 75.36 passes/s] \n",
      "Running MIL backend_mlprogram pipeline: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:00<00:00, 166.27 passes/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mCoreML Pipeline:\u001b[0m starting pipeline with coremltools 8.3.0...\n",
      "\u001b[34m\u001b[1mCoreML Pipeline:\u001b[0m pipeline success\n",
      "\u001b[34m\u001b[1mCoreML:\u001b[0m export success ‚úÖ 9.0s, saved as 'yolo11s.mlpackage' (18.3 MB)\n",
      "\n",
      "Export complete (9.3s)\n",
      "Results saved to \u001b[1m/Volumes/T7 Shield/MLCommon/yolo\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolo11s.mlpackage imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolo11s.mlpackage imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Ultralytics 8.3.220 üöÄ Python-3.11.13 torch-2.9.0 CPU (Apple M1 Pro)\n",
      "Loading yolo11s.mlpackage for CoreML inference...\n",
      "Setting batch=1 input of shape (1, 3, 640, 640)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.1¬±0.0 ms, read: 116.0¬±27.5 MB/s, size: 90.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Volumes/T7 Shield/MLCommon/yolo/datasets/coco/labels/val2017.cache... 4952 images, 48 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5000/5000 13.1Mit/s 0.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5000/5000 41.7it/s 1:60<0.0ss\n",
      "                   all       5000      36335      0.696      0.573      0.663      0.525\n",
      "Speed: 0.6ms preprocess, 14.5ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Loading yolo11s.mlpackage for CoreML inference...\n",
      "WARNING ‚ö†Ô∏è \n",
      "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "[yolo11s][CoreML] mAP50-95=0.5252 | mAP50=0.6634 | speed(ms) pre/inf/post=0.6414186112233438/14.473158956121187/0.08961321687093005\n",
      "[yolo11s][CoreML] predict: 5000 imgs, 132.58s, 37.71 img/s\n",
      "Ultralytics 8.3.220 üöÄ Python-3.11.13 torch-2.9.0 CPU (Apple M1 Pro)\n",
      "YOLO11s summary (fused): 100 layers, 9,443,760 parameters, 0 gradients, 21.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11s.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 300, 6) (18.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 22...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.71...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 1.7s, saved as 'yolo11s.onnx' (36.3 MB)\n",
      "\n",
      "Export complete (2.0s)\n",
      "Results saved to \u001b[1m/Volumes/T7 Shield/MLCommon/yolo\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolo11s.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolo11s.onnx imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Ultralytics 8.3.220 üöÄ Python-3.11.13 torch-2.9.0 CPU (Apple M1 Pro)\n",
      "Loading yolo11s.onnx for ONNX Runtime inference...\n",
      "Using ONNX Runtime 1.22.1 CPUExecutionProvider\n",
      "Setting batch=1 input of shape (1, 3, 640, 640)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.1¬±0.0 ms, read: 205.6¬±52.7 MB/s, size: 198.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Volumes/T7 Shield/MLCommon/yolo/datasets/coco/labels/val2017.cache... 4952 images, 48 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5000/5000 11.5Mit/s 0.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5000/5000 9.5it/s 8:47<0.3ss\n",
      "                   all       5000      36335      0.691      0.574      0.664      0.526\n",
      "Speed: 0.6ms preprocess, 91.9ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Loading yolo11s.onnx for ONNX Runtime inference...\n",
      "Using ONNX Runtime 1.22.1 CPUExecutionProvider\n",
      "WARNING ‚ö†Ô∏è \n",
      "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "[yolo11s][ONNX]   mAP50-95=0.5262 | mAP50=0.6638 | speed(ms) pre/inf/post=0.6416417621076107/91.89559824682074/0.12353788508335128\n",
      "[yolo11s][ONNX]   predict: 5000 imgs, 544.68s, 9.18 img/s\n",
      "\n",
      "Done. Metrics appended to: /Volumes/T7 Shield/MLCommon/yolo/runs_coco_val/metrics_s.txt\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "import platform\n",
    "from ultralytics.utils.downloads import download\n",
    "import zipfile\n",
    "\n",
    "\n",
    "VAL_DIR = Path(\"/yolo/datasets/coco/images/val2017\")\n",
    "DATA_YAML_PATH = \"/yolo/datasets/coco_val_only.yaml\"\n",
    "OUT_DIR = Path(\"/yolo/runs_coco_val\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODELS_TO_TEST = [\"yolo11s.pt\"] #\"yolo11m.pt\", \"yolo11l.pt\"\n",
    "IMGSZ = 640\n",
    "CONF = 0.25\n",
    "LIMIT = None                     \n",
    "RUN_THROUGHPUT = True            \n",
    "METRICS_TXT = OUT_DIR / \"metrics_small.txt\"\n",
    "\n",
    "\n",
    "\n",
    "def count_images(folder: Path) -> int:\n",
    "    return sum(1 for _ in folder.glob(\"*.jpg\"))\n",
    "\n",
    "def export_if_needed(model: YOLO, fmt: str, name_hint: str) -> str:\n",
    "    if fmt == \"coreml\":\n",
    "        target = OUT_DIR / f\"{name_hint}.mlpackage\"\n",
    "    elif fmt == \"onnx\":\n",
    "        target = OUT_DIR / f\"{name_hint}.onnx\"\n",
    "    else:\n",
    "        raise ValueError(\"fmt must be 'coreml' or 'onnx'\")\n",
    "    if target.exists():\n",
    "        return str(target)\n",
    "    return model.export(format=fmt, imgsz=IMGSZ, nms=True)\n",
    "\n",
    "\n",
    "def eval_map_and_speed(yolo_model: YOLO, project_dir: Path, run_name: str):\n",
    "    r = yolo_model.val(\n",
    "        data=DATA_YAML_PATH,\n",
    "        split=\"val\",\n",
    "        imgsz=IMGSZ,\n",
    "        plots=True,                 \n",
    "        save_json=False,           \n",
    "        project=str(project_dir),\n",
    "        name=run_name,\n",
    "        verbose=False,\n",
    "    )\n",
    "    spd = getattr(r, \"speed\", {}) or {}\n",
    "    return {\n",
    "        \"map50_95\": getattr(r.box, \"map\", None),\n",
    "        \"map50\": getattr(r.box, \"map50\", None),\n",
    "        \"speed_ms_pre\": spd.get(\"preprocess\"),\n",
    "        \"speed_ms_inf\": spd.get(\"inference\"),\n",
    "        \"speed_ms_post\": spd.get(\"postprocess\"),\n",
    "    }\n",
    "\n",
    "def predict_and_time_stream(yolo_model: YOLO, name: str, engine_tag: str, val_dir: Path):\n",
    "    from time import perf_counter\n",
    "    t0, n = perf_counter(), 0\n",
    "    for _ in yolo_model.predict(\n",
    "        source=str(val_dir),\n",
    "        imgsz=IMGSZ,\n",
    "        conf=CONF,\n",
    "        save=False,                              \n",
    "        project=str(OUT_DIR / \"predictions\"),    \n",
    "        name=f\"{name}_{engine_tag}\",\n",
    "        stream=True,                             \n",
    "        max_det=300,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        n += 1\n",
    "    dt = perf_counter() - t0\n",
    "    return {\"images\": n, \"seconds\": dt, \"img_per_s\": (n / dt) if dt else 0.0}\n",
    "\n",
    "def log_line(s: str, fh):\n",
    "    print(s)\n",
    "    fh.write(s + \"\\n\")\n",
    "\n",
    "\n",
    "def ensure_coco_val_labels_from_pack(coco_root: Path):\n",
    "    labels_val = coco_root / \"labels\" / \"val2017\"\n",
    "    labels_val.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if not any(labels_val.glob(\"*.txt\")):\n",
    "        datasets_dir = coco_root.parent\n",
    "        zip_path = datasets_dir / \"coco2017labels.zip\"\n",
    "        if not zip_path.exists():\n",
    "            download(\"https://ultralytics.com/assets/coco2017labels.zip\", dir=str(datasets_dir))\n",
    "        with zipfile.ZipFile(zip_path) as zf:\n",
    "            zf.extractall(datasets_dir)\n",
    "    try:\n",
    "        (coco_root / \"labels\").chmod(0o755)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def run():\n",
    "    assert VAL_DIR.exists(), f\"{VAL_DIR} does not exist\"\n",
    "\n",
    "  \n",
    "    eval_dir = VAL_DIR\n",
    "    if LIMIT:\n",
    "        subset_dir = OUT_DIR / f\"val2017_subset_{LIMIT}\"\n",
    "        subset_dir.mkdir(parents=True, exist_ok=True)\n",
    "        if not any(subset_dir.glob(\"*.jpg\")):\n",
    "            for i, p in enumerate(sorted(VAL_DIR.glob(\"*.jpg\"))):\n",
    "                if i >= LIMIT: break\n",
    "                try:\n",
    "                    (subset_dir / p.name).symlink_to(p)\n",
    "                except Exception:\n",
    "                    import shutil; shutil.copy2(p, subset_dir / p.name)\n",
    "        eval_dir = subset_dir\n",
    "\n",
    "    coco_root = VAL_DIR.parent.parent  \n",
    "    ensure_coco_val_labels_from_pack(coco_root)\n",
    "\n",
    "    with open(METRICS_TXT, \"a\", encoding=\"utf-8\") as fh:\n",
    "        log_line(\"=\" * 80, fh)\n",
    "        log_line(f\"Timestamp: {datetime.now().isoformat(timespec='seconds')}\", fh)\n",
    "        log_line(f\"Host: {platform.platform()} | Python: {platform.python_version()} | Processor: {platform.processor()}\", fh)\n",
    "        log_line(f\"VAL_DIR: {eval_dir}\", fh)\n",
    "        log_line(f\"DATA_YAML: {DATA_YAML_PATH}\", fh)\n",
    "        log_line(f\"Models: {', '.join(MODELS_TO_TEST)}\", fh)\n",
    "        log_line(\"-\" * 80, fh)\n",
    "\n",
    "        total_imgs = count_images(eval_dir)\n",
    "        log_line(f\"Discovered images: {total_imgs}\", fh)\n",
    "\n",
    "        for model_name in MODELS_TO_TEST:\n",
    "            base = Path(model_name).stem\n",
    "            log_line(f\"\\n[{base}] --- EXPORT + EVAL ---\", fh)\n",
    "\n",
    "            try:\n",
    "                torch_model = YOLO(model_name)\n",
    "            except Exception as e:\n",
    "                log_line(f\"[{base}] ERROR: failed to load weights: {e}\", fh)\n",
    "                continue\n",
    "\n",
    "            # Core ML / ANE\n",
    "            try:\n",
    "                mlp_path = export_if_needed(torch_model, \"coreml\", base)\n",
    "                ane = YOLO(mlp_path, task=\"detect\")\n",
    "                m_ap = eval_map_and_speed(ane, OUT_DIR / \"eval\", f\"{base}_coreml\")\n",
    "                if RUN_THROUGHPUT:\n",
    "                    thr = predict_and_time_stream(ane, base, \"coreml\", eval_dir)\n",
    "                    log_line(f\"[{base}][CoreML] predict: {thr['images']} imgs, {thr['seconds']:.2f}s, {thr['img_per_s']:.2f} img/s\", fh)\n",
    "                log_line(f\"[{base}][CoreML] mAP50-95={m_ap['map50_95']:.4f} | mAP50={m_ap['map50']:.4f} | \"\n",
    "                         f\"speed(ms) pre/inf/post={m_ap['speed_ms_pre']}/{m_ap['speed_ms_inf']}/{m_ap['speed_ms_post']}\", fh)\n",
    "            except Exception as e:\n",
    "                log_line(f\"[{base}][CoreML] ERROR: {e}\", fh)\n",
    "\n",
    "            # ONNX (CPU on macOS)\n",
    "            try:\n",
    "                onnx_path = export_if_needed(torch_model, \"onnx\", base)\n",
    "                ort = YOLO(onnx_path, task=\"detect\")\n",
    "                m_ap = eval_map_and_speed(ort, OUT_DIR / \"eval\", f\"{base}_onnx\")\n",
    "                if RUN_THROUGHPUT:\n",
    "                    thr = predict_and_time_stream(ort, base, \"onnx\", eval_dir)\n",
    "                    log_line(f\"[{base}][ONNX]   predict: {thr['images']} imgs, {thr['seconds']:.2f}s, {thr['img_per_s']:.2f} img/s\", fh)\n",
    "                log_line(f\"[{base}][ONNX]   mAP50-95={m_ap['map50_95']:.4f} | mAP50={m_ap['map50']:.4f} | \"\n",
    "                         f\"speed(ms) pre/inf/post={m_ap['speed_ms_pre']}/{m_ap['speed_ms_inf']}/{m_ap['speed_ms_post']}\", fh)\n",
    "            except Exception as e:\n",
    "                log_line(f\"[{base}][ONNX]   ERROR: {e}\", fh)\n",
    "\n",
    "        log_line(\"\\nDone. Metrics appended to: \" + str(METRICS_TXT), fh)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7e928e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlperf51",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
